import torch
import torch.nn as nn
import os
import sys

# ================= è·¯å¾„ä¿®å¤ =================
current_dir = os.path.dirname(os.path.abspath(__file__))
wavlm_source_dir = os.path.join(current_dir, "..", "src", "WavLM")
wavlm_source_dir = os.path.abspath(wavlm_source_dir)

if wavlm_source_dir not in sys.path:
    sys.path.insert(0, wavlm_source_dir)

try:
    from WavLM import WavLM, WavLMConfig
except ImportError:
    raise ImportError(f"âŒ æ— æ³•å¯¼å…¥ WavLMï¼Œè¯·æ£€æŸ¥ src/WavLM æ˜¯å¦å­˜åœ¨ã€‚")
# ===========================================

class WavLMWrapper(nn.Module):
    def __init__(self, checkpoint_path=None):
        super().__init__()
        
        if checkpoint_path is None:
            checkpoint_path = os.path.join(current_dir, "..", "pretrained", "wavlm.pt")
        
        if not os.path.exists(checkpoint_path):
            raise FileNotFoundError(f"âŒ æ‰¾ä¸åˆ° WavLM æƒé‡æ–‡ä»¶: {checkpoint_path}")

        print(f"æ­£åœ¨åŠ è½½ WavLM (å¤šå±‚æ¨¡å¼): {checkpoint_path}")
        
        checkpoint = torch.load(checkpoint_path, map_location="cpu")
        cfg = WavLMConfig(checkpoint['cfg'])
        self.model = WavLM(cfg)
        self.model.load_state_dict(checkpoint['model'])
        self.model.eval()

    def extract_features(self, wav):
        """ä¿æŒå…¼å®¹æ—§ä»£ç çš„æ¥å£ (åªè¿”å›æœ€åä¸€å±‚)"""
        # æ³¨æ„ï¼šè¿™é‡Œå–[-1]è¡¨ç¤ºæœ€åä¸€å±‚
        return self.extract_all_layers(wav)[-1]

    def extract_all_layers(self, wav):
        """
        ğŸ”´ ç»ˆæä¿®å¤ç‰ˆï¼šå¤„ç†å„ç§è¿”å›ç±»å‹
        Returns: [13, Batch, Time, 768] (13 = 1 embedding + 12 layers)
        """
        # ç»´åº¦è°ƒæ•´
        if wav.dim() == 3 and wav.shape[1] == 1: wav = wav.squeeze(1)
        if wav.dim() == 1: wav = wav.unsqueeze(0)

        # å½’ä¸€åŒ–
        if self.model.cfg.normalize:
            wav = torch.nn.functional.layer_norm(wav, wav.shape)

        # æå–ç‰¹å¾
        results = self.model.extract_features(wav, padding_mask=None, ret_layer_results=True)
        
        # 1. è§£åŒ… results
        if isinstance(results, tuple) and len(results) == 2:
            rep, layer_results = results
        else:
            rep = results
            layer_results = None

        # ğŸ”´ å…³é”®ä¿®å¤ï¼šæ£€æŸ¥ rep æ˜¯å¦ä¹Ÿæ˜¯ tuple
        # WavLM æœ‰æ—¶è¿”å› (features, padding_mask) ä½œä¸º rep
        if isinstance(rep, tuple):
            rep = rep[0]

        # 2. é˜²å¾¡æ€§å¤„ç† (Fallback)
        if layer_results is None:
            # print("âš ï¸ è­¦å‘Š: WavLM æœªè¿”å›ä¸­é—´å±‚ï¼Œä½¿ç”¨æœ€åä¸€å±‚å¤åˆ¶å¡«å……ã€‚") 
            # æ­¤æ—¶ rep å·²ç»æ˜¯ tensor äº†ï¼Œå¯ä»¥å®‰å…¨ unsqueeze
            stacked = rep.unsqueeze(0).repeat(13, 1, 1, 1)
            return stacked

        # 3. æ­£å¸¸å¤„ç† list
        layers = []
        for x in layer_results:
            # layer_results çš„é¡¹å¯èƒ½æ˜¯ (hidden_state, attn)
            if isinstance(x, tuple):
                layers.append(x[0])
            else:
                layers.append(x)
        
        # å †å : [Layers, Batch, Time, Dim]
        stacked = torch.stack(layers)
        
        return stacked

if __name__ == "__main__":
    wrapper = WavLMWrapper()
    x = torch.randn(2, 16000)
    out = wrapper.extract_all_layers(x)
    print(f"âœ… å¤šå±‚æå–æˆåŠŸï¼Œè¾“å‡ºç»´åº¦: {out.shape} (é¢„æœŸ: [13, 2, T, 768])")