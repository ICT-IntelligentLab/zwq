import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from tqdm import tqdm

# æ˜¾å¼å¯¼å…¥
from src.dataset import EmotionSegmentDataset
from src.model import DynamicEmotionModel

# ================= å¾®è°ƒé…ç½®å‚æ•° (å…³é”®ä¿®æ”¹) =================
# 1. å‡å° Batch Size é˜²æ­¢æ˜¾å­˜çˆ†ç‚¸ (å¦‚æœæ˜¾å­˜å¤Ÿå¤§ï¼Œå¯å°è¯• 4)
BATCH_SIZE = 2          

# 2. ä¿æŒæä½å­¦ä¹ ç‡ (å¾®è°ƒé»„é‡‘æ³•åˆ™)
LR = 1e-5               

# 3. å¢åŠ è½®æ•°ï¼Œå¾®è°ƒéœ€è¦è€å¿ƒ
EPOCHS = 30             

DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
WAVLM_PATH = "pretrained/wavlm.pt" 

# 4. ä¿®æ”¹ä¿å­˜è·¯å¾„ï¼Œé¿å…è¦†ç›–ä¹‹å‰çš„æ¨¡å‹
SAVE_DIR = "models_finetune"     
# ========================================================

# CCC Loss å®šä¹‰ (ä¿æŒä¸å˜)
class CCCLoss(nn.Module):
    def __init__(self):
        super().__init__()

    def forward(self, x, y):
        x_mean = torch.mean(x, dim=0)
        y_mean = torch.mean(y, dim=0)
        x_var = torch.var(x, dim=0, unbiased=False)
        y_var = torch.var(y, dim=0, unbiased=False)
        cov = torch.mean((x - x_mean) * (y - y_mean), dim=0)
        numerator = 2 * cov
        denominator = x_var + y_var + (x_mean - y_mean) ** 2 + 1e-8
        ccc = numerator / denominator
        loss = 1.0 - torch.mean(ccc)
        return loss

def train():
    os.makedirs(SAVE_DIR, exist_ok=True)

    print("ğŸš€ å¯åŠ¨å…¨é‡å¾®è°ƒ (Fine-tuning) æ¨¡å¼...")
    print(f"é…ç½®: Batch={BATCH_SIZE}, LR={LR}, Epochs={EPOCHS}")

    # 1. åŠ è½½æ•°æ®
    print("æ­£åœ¨åŠ è½½å…¨é‡æ•°æ®é›†...")
    train_ds = EmotionSegmentDataset("data/train.csv", project_root=".")
    val_ds = EmotionSegmentDataset("data/val.csv", project_root=".")

    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)
    val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)

    print(f"è®­ç»ƒé›†: {len(train_ds)} | éªŒè¯é›†: {len(val_ds)}")

    # 2. åˆå§‹åŒ–æ¨¡å‹
    print(f"æ­£åœ¨åŠ è½½æ¨¡å‹ (Device: {DEVICE})...")
    model = DynamicEmotionModel(wavlm_path=WAVLM_PATH).to(DEVICE)
    
    # =======================================================
    # ğŸ”´ æ ¸å¿ƒä¿®æ”¹ï¼šè§£å†» WavLM (Unfreeze)
    # =======================================================
    print("ğŸ”“ å·²è§£å†» WavLM å‚æ•°ï¼Œå¼€å§‹è¿›è¡Œç«¯åˆ°ç«¯å¾®è°ƒ...")
    for param in model.wavlm.model.parameters():
        param.requires_grad = True  # æ‰“å¼€æ¢¯åº¦å¼€å…³
    # =======================================================

    # 3. å®šä¹‰ä¼˜åŒ–å™¨
    # æ³¨æ„ï¼šå¾®è°ƒæ—¶ï¼ŒWeight Decay éå¸¸é‡è¦ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆ
    optimizer = optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-2)
    
    mse_criterion = nn.MSELoss()
    ccc_criterion = CCCLoss()

    best_loss = float('inf')

    # 4. è®­ç»ƒå¾ªç¯
    for epoch in range(EPOCHS):
        model.train()
        train_loss = 0.0
        
        # è¿™é‡Œçš„ tqdm ä¼šå˜æ…¢ï¼Œå› ä¸ºåå‘ä¼ æ’­è¦è®¡ç®— WavLM çš„ 9000ä¸‡ä¸ªå‚æ•°
        loop = tqdm(train_loader, desc=f"Epoch {epoch+1}/{EPOCHS} [Finetune]")
        
        for wav, labels in loop:
            wav = wav.to(DEVICE)       
            labels = labels.to(DEVICE) 

            # å‰å‘ä¼ æ’­
            preds = model(wav)         
            
            # æ··åˆ Loss
            loss_mse = mse_criterion(preds, labels)
            loss_ccc = ccc_criterion(preds, labels)
            loss = 0.5 * loss_mse + 0.5 * loss_ccc

            # åå‘ä¼ æ’­
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            train_loss += loss.item()
            loop.set_postfix(loss=loss.item())

        avg_train_loss = train_loss / len(train_loader)

        # 5. éªŒè¯å¾ªç¯
        model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for wav, labels in tqdm(val_loader, desc=f"Epoch {epoch+1}/{EPOCHS} [Val]"):
                wav = wav.to(DEVICE)
                labels = labels.to(DEVICE)
                
                preds = model(wav)
                
                l_mse = mse_criterion(preds, labels)
                l_ccc = ccc_criterion(preds, labels)
                loss = 0.5 * l_mse + 0.5 * l_ccc
                
                val_loss += loss.item()

        avg_val_loss = val_loss / len(val_loader)

        print(f"Epoch {epoch+1} ç»“æŸ: Train Loss = {avg_train_loss:.4f} | Val Loss = {avg_val_loss:.4f}")

        # 6. ä¿å­˜æœ€ä½³æ¨¡å‹
        if avg_val_loss < best_loss:
            best_loss = avg_val_loss
            save_path = os.path.join(SAVE_DIR, "best_model_finetuned.pth")
            torch.save(model.state_dict(), save_path)
            print(f"ğŸ‰ å‘ç°æ›´ä¼˜æ¨¡å‹ (Loss: {best_loss:.4f})ï¼Œå·²ä¿å­˜åˆ°: {save_path}")
        
        print("-" * 50)

if __name__ == "__main__":
    train()